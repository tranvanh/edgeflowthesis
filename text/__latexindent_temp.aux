\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `-\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\changetocdepth  {3}}
\babel@aux{english}{}
\babel@aux{english}{}
\HyPL@Entry{2<</S/r>>}
\babel@aux{czech}{}
\babel@aux{english}{}
\babel@aux{czech}{}
\babel@aux{english}{}
\HyPL@Entry{14<</S/D>>}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{Introduction}{1}{chapter*.7}\protected@file@percent }
\newlabel{ch:introduction}{{\M@TitleReference {}{Introduction}}{1}{Introduction}{chapter*.7}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{Introduction}{3}{chapter*.8}\protected@file@percent }
\newlabel{ch:introduction}{{\M@TitleReference {}{Introduction}}{3}{Introduction}{chapter*.8}{}}
\citation{mcculloch1943logical}
\citation{designimplentationcc}
\citation{bengio2017deep}
\citation{neural2016krishtopa}
\citation{perceptronprobabmodel}
\citation{matous}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Neural Networks}{5}{chapter.1}\protected@file@percent }
\newlabel{ch:neural_network}{{\M@TitleReference {1}{Neural Networks}}{5}{Neural Networks}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Artificial Neuron}{5}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Perceptron}{5}{subsection.1.1.1}\protected@file@percent }
\citation{matous}
\citation{matous}
\citation{nndl2015michaelnielsen}
\citation{rojas2013neural}
\citation{matous}
\citation{leskovec2020mining}
\citation{matous}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Perceptron \cite  {matous}\relax }}{6}{figure.caption.9}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:perceptron}{{\M@TitleReference {1.1}{Perceptron \cite  {matous}\relax }}{6}{Perceptron \cite {matous}\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Sigmoid Neuron}{6}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Activation Function}{6}{subsection.1.1.3}\protected@file@percent }
\citation{7typesactivationfunctions}
\citation{matous}
\citation{matous}
\citation{matous}
\newlabel{step_function}{{\M@TitleReference {1.2a}{Sigmoid Neuron}}{7}{Subfigure 1 1.2a}{subfigure.1.2.1}{}}
\newlabel{sub@step_function}{{(a)}{a}{Subfigure 1 1.2a\relax }{subfigure.1.2.1}{}}
\newlabel{sigmoid_function}{{\M@TitleReference {1.2b}{Sigmoid Neuron}}{7}{Subfigure 1 1.2b}{subfigure.1.2.2}{}}
\newlabel{sub@sigmoid_function}{{(b)}{b}{Subfigure 1 1.2b\relax }{subfigure.1.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Comparison between step function and sigmoid function\relax }}{7}{figure.caption.10}\protected@file@percent }
\newlabel{sigmoid_neuron}{{\M@TitleReference {1.2}{Comparison between step function and sigmoid function\relax }}{7}{Comparison between step function and sigmoid function\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Step function}}}{7}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Sigmoid function}}}{7}{subfigure.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3.1}Sigmoid Function}{7}{subsubsection.1.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3.2}Hyperbolic Tangent}{7}{subsubsection.1.1.3.2}\protected@file@percent }
\citation{leskovec2020mining}
\citation{matous}
\citation{matous}
\citation{matous}
\citation{7typesactivationfunctions}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Hyperbolic tangent \cite  {matous}\relax }}{8}{figure.caption.11}\protected@file@percent }
\newlabel{fig:hyperbolictangent}{{\M@TitleReference {1.3}{Hyperbolic tangent \cite  {matous}\relax }}{8}{Hyperbolic tangent \cite {matous}\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3.3}Rectified Linear Unit}{8}{subsubsection.1.1.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Rectified Linear Unit \cite  {matous}\relax }}{8}{figure.caption.12}\protected@file@percent }
\newlabel{fig:relu}{{\M@TitleReference {1.4}{Rectified Linear Unit \cite  {matous}\relax }}{8}{Rectified Linear Unit \cite {matous}\relax }{figure.caption.12}{}}
\citation{lipton2015critical}
\citation{ffnbrilliant}
\citation{mainTypesANN}
\citation{lipton2015critical}
\citation{matous}
\citation{matous}
\citation{Goodfellow-et-al-2016}
\citation{birlliantbackprop}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3.4}Softmax}{9}{subsubsection.1.1.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Types of Neural Networks}{9}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Feed-forward Networks}{9}{subsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1.1}Cost Function}{9}{subsubsection.1.2.1.1}\protected@file@percent }
\citation{birlliantbackprop}
\citation{mlmastery}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Fully connected Feed-forward Neural Network \cite  {matous}\relax }}{10}{figure.caption.13}\protected@file@percent }
\newlabel{fig:ffn}{{\M@TitleReference {1.5}{Fully connected Feed-forward Neural Network \cite  {matous}\relax }}{10}{Fully connected Feed-forward Neural Network \cite {matous}\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1.2}Backpropagation}{10}{subsubsection.1.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Convolutional Neural Networks}{10}{subsection.1.2.2}\protected@file@percent }
\citation{Goodfellow-et-al-2016}
\citation{mathworkscnn}
\citation{compguideCnn}
\citation{compguideCnn}
\citation{compguideCnn}
\citation{compguideCnn}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2.1}Convolutional Layer}{11}{subsubsection.1.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Convolution of an 5x5x1 image with 3x3x1 kernel \cite  {compguideCnn}\relax }}{11}{figure.caption.14}\protected@file@percent }
\newlabel{fig:cnn_conv}{{\M@TitleReference {1.6}{Convolution of an 5x5x1 image with 3x3x1 kernel \cite  {compguideCnn}\relax }}{11}{Convolution of an 5x5x1 image with 3x3x1 kernel \cite {compguideCnn}\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2.2}Pooling Layer}{11}{subsubsection.1.2.2.2}\protected@file@percent }
\citation{compguideCnn}
\citation{compguideCnn}
\citation{compguideCnn}
\citation{graph}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Types of pooling \cite  {compguideCnn}\relax }}{12}{figure.caption.15}\protected@file@percent }
\newlabel{fig:cnn_pooling}{{\M@TitleReference {1.7}{Types of pooling \cite  {compguideCnn}\relax }}{12}{Types of pooling \cite {compguideCnn}\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Graph Neural Networks}{12}{subsection.1.2.3}\protected@file@percent }
\citation{stanford}
\citation{stanford}
\citation{stanford}
\citation{stanford}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3.1}Node embedding}{13}{subsubsection.1.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Layer-2 embedding applied on node $A$ aggregating infromation from its neighborhood \cite  {stanford}\relax }}{13}{figure.caption.16}\protected@file@percent }
\newlabel{fig:gnn_layers}{{\M@TitleReference {1.8}{Layer-2 embedding applied on node $A$ aggregating infromation from its neighborhood \cite  {stanford}\relax }}{13}{Layer-2 embedding applied on node $A$ aggregating infromation from its neighborhood \cite {stanford}\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Neural network of each node for given input node graph \cite  {stanford}\relax }}{14}{figure.caption.17}\protected@file@percent }
\newlabel{fig:gnn_graph}{{\M@TitleReference {1.9}{Neural network of each node for given input node graph \cite  {stanford}\relax }}{14}{Neural network of each node for given input node graph \cite {stanford}\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3.2}Geometric graphs}{14}{subsubsection.1.2.3.2}\protected@file@percent }
